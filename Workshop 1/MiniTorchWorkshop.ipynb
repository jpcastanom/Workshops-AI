{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTp5HHtW98dK"
   },
   "source": [
    "## From-Scratch “MiniTorch” — Notebook Overview\n",
    "\n",
    "In this notebook we will **implement a minimal deep-learning framework from scratch** (“miniTorch”) and use it to train a simple neural network on the **MNIST** dataset as a toy problem.\n",
    "\n",
    "### Objectives\n",
    "- **Layers:** Implement core layers (e.g., `Linear`, `Dropout`, `BatchNorm1D`) with clean APIs.\n",
    "- **Forward & Backward:** Write explicit **forward** and **backward** passes for every layer (no autograd).\n",
    "- **Losses:** Implement a **cross-entropy from logits** loss.\n",
    "- **Training Loop:** Build an epoch-based loop with **train/validation** splits and metrics.\n",
    "- **Optimization:** Perform **manual SGD** parameter updates (learning rate, gradient averaging, etc.).\n",
    "\n",
    "### Scope & Assumptions\n",
    "- We will **not** use PyTorch autograd; gradients are computed **manually**.\n",
    "- Tensors are used only as numerical containers and for basic ops (matmul, sum, etc.).\n",
    "- We adopt PyTorch-style `net.train()` / `net.eval()` mode switches for realism.\n",
    "- The dataset is **MNIST** (28×28 grayscale digits, 10 classes), serving as a **toy setting** to validate our implementation.\n",
    "\n",
    "### What You’ll Get By the End\n",
    "- A working “miniTorch” stack: layers → forward/backward → training loop → optimizer.\n",
    "- Clear, student-friendly code that mirrors real libraries while remaining small and inspectable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIe_sdxH-kZ-"
   },
   "source": [
    "## 1. Loading the MNIST Dataset\n",
    "\n",
    "We will use the **MNIST** dataset — a classic benchmark of **28×28 grayscale images** of handwritten digits (0–9).  \n",
    "It contains:\n",
    "- **60,000** training images\n",
    "- **10,000** test images\n",
    "\n",
    "### Steps:\n",
    "1. **Download & Transform**  \n",
    "   - Use `torchvision.datasets.MNIST` to automatically download the data.\n",
    "   - Convert images to tensors and normalize pixel values to the range \\([-1, 1]\\).\n",
    "\n",
    "2. **Split into Train & Validation**  \n",
    "   - The official training set (60,000 samples) will be split into:\n",
    "     - **Training set:** 80% of the data (48,000 images).\n",
    "     - **Validation set:** 20% of the data (12,000 images).\n",
    "   - The split allows us to monitor generalization during training.\n",
    "\n",
    "3. **Test Set**  \n",
    "   - The test set (10,000 images) is kept separate and **only used at the end** to report final performance.\n",
    "\n",
    "### Why Split into Validation?\n",
    "The validation set helps track **overfitting**:  \n",
    "- If training accuracy keeps increasing but validation accuracy stalls or decreases, the model is memorizing instead of generalizing.\n",
    "\n",
    "### Summary\n",
    "- **Training set:** update model weights.\n",
    "- **Validation set:** tune hyperparameters & monitor generalization.\n",
    "- **Test set:** final unbiased evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "09Qu96B35Wdu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "# pick the seed for reproducibility - change it to explore the effects of random variations\n",
    "np.random.seed(0)\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TlUCB_zK6Scx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TIBpYf996Zit"
   },
   "outputs": [],
   "source": [
    "# Define transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load full train dataset\n",
    "full_trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Split into train and validation\n",
    "train_size = int(0.8 * len(full_trainset))\n",
    "val_size = len(full_trainset) - train_size\n",
    "trainset, valset = random_split(full_trainset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Test data\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1755027165406,
     "user": {
      "displayName": "Juan David Martinez Vargas",
      "userId": "15315348669826032119"
     },
     "user_tz": 300
    },
    "id": "-t4LZI997v-6",
    "outputId": "e31049c8-5989-441d-f295-ba89a8ec92d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Example: Iterate over a few batches\n",
    "for images, labels in trainloader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1755027168052,
     "user": {
      "displayName": "Juan David Martinez Vargas",
      "userId": "15315348669826032119"
     },
     "user_tz": 300
    },
    "id": "UqqrP50f75ns",
    "outputId": "5eed2234-9e7a-46b5-856a-9c0ef4537c04"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check some examples\n",
    "for images, labels in trainloader:\n",
    "    # Denormalize the images for plotting\n",
    "    images = images * 0.5 + 0.5\n",
    "\n",
    "    # Plot the images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(9):  # Plot 9 images\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i][0], cmap='gray')  # images[i][0] for grayscale images\n",
    "        plt.title(f\"Label: {labels[i].item()}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwO8LEOd_CM5"
   },
   "source": [
    "## 2. Implementing the Linear Layer\n",
    "\n",
    "The **Linear** (or fully connected / dense) layer is one of the fundamental building blocks of neural networks.  \n",
    "It performs a **linear transformation** of the input:\n",
    "\n",
    "$$\n",
    "Z = XW + b\n",
    "$$\n",
    "\n",
    "- **Forward pass:**  \n",
    "  Takes the input $X \\in \\mathbb{R}^{\\text{batch} \\times n_{\\text{in}}}$ and computes the weighted sum using the weight matrix $W \\in \\mathbb{R}^{n_{\\text{in}} \\times n_{\\text{out}}}$ and bias vector $b \\in \\mathbb{R}^{n_{\\text{out}}}$.\n",
    "- **Backward pass:**  \n",
    "  Computes the gradients of the loss with respect to $W$, $b$, and $X$ so we can update the parameters during training.\n",
    "- **Update step:**  \n",
    "  Applies a gradient descent step to $W$ and $b$ using the computed gradients and a learning rate.\n",
    "\n",
    "Below is a template where you will fill in the missing pieces (`# TODO`) to implement forward, backward, and update logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1755028362796,
     "user": {
      "displayName": "Juan David Martinez Vargas",
      "userId": "15315348669826032119"
     },
     "user_tz": 300
    },
    "id": "A20c5lPy8dCQ",
    "outputId": "9bddd4f9-679c-483f-b526-14fa628a2035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "class Linear:\n",
    "    \"\"\"\n",
    "    A simple fully connected (dense) layer.\n",
    "    Performs a linear transformation:  Z = XW + b\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nin, nout, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Initialize the layer parameters.\n",
    "        \"\"\"\n",
    "        # Initialize weights from a normal distribution\n",
    "        self.W = torch.randn(nin, nout, device=device, requires_grad=False)\n",
    "        # Initialize biases to zero\n",
    "        self.b = torch.zeros(nout, device=device, requires_grad=False)\n",
    "        self.training = True  # for compatibility with Dropout/BatchNorm\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Switch to training mode.\"\"\"\n",
    "        self.training = True\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"Switch to evaluation mode.\"\"\"\n",
    "        self.training = False\n",
    "        return self\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass: compute the output of the layer.\n",
    "        \"\"\"\n",
    "        self.X = X  # store for backward pass\n",
    "        # TODO: Implement Z = XW + b\n",
    "        Z = torch.matmul(X, self.W) + self.b\n",
    "        return Z\n",
    "\n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients w.r.t. W, b, and X.\n",
    "        \"\"\"\n",
    "        # TODO: Compute self.dW, self.db, and self.dX\n",
    "        batch_size = self.X.size(0)\n",
    "        self.dW = torch.matmul(self.X.T, dZ) / batch_size\n",
    "        self.db = torch.sum(dZ, dim=0) / batch_size\n",
    "        self.dX = torch.matmul(dZ, self.W.T)\n",
    "        return self.dX\n",
    "\n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Update parameters using gradient descent.\n",
    "        \"\"\"\n",
    "        # TODO: Update W and b using self.dW and self.db\n",
    "        self.W -= lr * self.dW\n",
    "        self.b -= lr * self.db\n",
    "\n",
    "# Example usage\n",
    "nin = 4\n",
    "nout = 3\n",
    "n_batch = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Simulated input tensor\n",
    "X = torch.randn(n_batch, nin).to(device)\n",
    "\n",
    "# Create an instance of the Linear class and compute the linear transformation\n",
    "net = Linear(nin, nout, device=device)\n",
    "Z = net.forward(X)\n",
    "print(Z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u651tX8vVVPp"
   },
   "source": [
    "## 3. CrossEntropyFromLogits Loss\n",
    "\n",
    "To train a neural network for **classification**, we need a loss function that measures how well the predicted class scores (logits) match the true labels.  \n",
    "A very common choice is the **Cross-Entropy Loss**, combined with the **Softmax** function.\n",
    "\n",
    "### Step 1: Softmax\n",
    "\n",
    "Given the logits for each sample:\n",
    "$$\n",
    "Z \\in \\mathbb{R}^{m \\times C}\n",
    "$$\n",
    "where $m$ is the batch size and $C$ is the number of classes,  \n",
    "the softmax function converts logits into probabilities:\n",
    "\n",
    "$$\n",
    "A_{i,j} = \\frac{\\exp(Z_{i,j})}{\\sum_{k=1}^{C} \\exp(Z_{i,k})}\n",
    "$$\n",
    "\n",
    "This ensures:\n",
    "- $A_{i,j} \\geq 0$ (all outputs are non-negative)\n",
    "- $\\sum_{j=1}^{C} A_{i,j} = 1$ (rows sum to 1, valid probability distribution).\n",
    "\n",
    "### Step 2: Cross-Entropy Loss\n",
    "\n",
    "If $Y_i$ is the true label for sample $i$ (an integer in $[0, C-1]$),  \n",
    "the cross-entropy loss for one sample is:\n",
    "\n",
    "$$\n",
    "\\ell_i = -\\log\\big( A_{i, Y_i} \\big)\n",
    "$$\n",
    "\n",
    "The loss over the batch is the average:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{m} \\sum_{i=1}^m \\ell_i\n",
    "= -\\frac{1}{m} \\sum_{i=1}^m \\log\\big( A_{i, Y_i} \\big)\n",
    "$$\n",
    "\n",
    "### Step 3: Gradient (Backward Pass)\n",
    "\n",
    "The derivative of the loss with respect to the logits is elegant:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial Z_{i,j}}\n",
    "= A_{i,j} - \\mathbf{1}[j = Y_i]\n",
    "$$\n",
    "\n",
    "That is:\n",
    "- For the correct class: $A_{i,Y_i} - 1$\n",
    "- For other classes: $A_{i,j}$\n",
    "\n",
    "This makes backpropagation very efficient.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Forward pass:** compute softmax + cross-entropy.  \n",
    "- **Backward pass:** subtract 1 from the probability of the true class.  \n",
    "\n",
    "This loss is standard for multi-class classification problems such as MNIST.\n",
    "\n",
    "---\n",
    "\n",
    "We can express this more compactly in **matrix form**.\n",
    "\n",
    "Let:\n",
    "- $ A \\in \\mathbb{R}^{m \\times C} $ be the matrix of softmax outputs,  \n",
    "- $ Y \\in \\mathbb{R}^{m \\times C} $ be the one-hot encoded true labels,  \n",
    "- $ m $ = batch size.  \n",
    "\n",
    "Then the gradient of the loss w.r.t. the logits $Z$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial Z} = \\frac{1}{m}\\,(A - Y)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Key Points:\n",
    "- The subtraction $$ A - Y $$ automatically applies the correct rule to all classes in all samples.\n",
    "- The factor $ \\tfrac{1}{m} $ appears if the loss is averaged across the batch (omit it if summing).\n",
    "- This compact vectorized form makes backpropagation efficient in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1755028466569,
     "user": {
      "displayName": "Juan David Martinez Vargas",
      "userId": "15315348669826032119"
     },
     "user_tz": 300
    },
    "id": "7ZYsEzaRBeKj",
    "outputId": "47620091-b361-4773-d075-f31634a9a434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5628)\n"
     ]
    }
   ],
   "source": [
    "class CrossEntropyFromLogits:\n",
    "    \"\"\"\n",
    "    Implements the combination of:\n",
    "    - Softmax activation (from raw logits)\n",
    "    - Cross-entropy loss\n",
    "\n",
    "    This is a common choice for multi-class classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, Z, Y):\n",
    "        \"\"\"\n",
    "        Forward pass: compute the cross-entropy loss from raw logits.\n",
    "\n",
    "        Args:\n",
    "            Z (torch.Tensor): Logits (unnormalized scores) of shape (batch_size, n_classes).\n",
    "            Y (torch.Tensor): True class indices of shape (batch_size,).\n",
    "\n",
    "        Returns:\n",
    "            loss torch.Tensor: Scalar value of the cross-entropy loss.\n",
    "        \"\"\"\n",
    "        self.Y = Y  # Store true labels for backward pass\n",
    "\n",
    "        # TODO: Compute softmax probabilities (convert logits to probabilities)\n",
    "        # self.A = ...\n",
    "        Z_shifted = Z - torch.max(Z, dim=1, keepdim=True)[0]\n",
    "        exp_Z = torch.exp(Z_shifted)\n",
    "        sum_exp_Z = torch.sum(exp_Z, dim=1, keepdim=True)\n",
    "        self.A = exp_Z / sum_exp_Z\n",
    "\n",
    "        # TODO: Compute log-softmax (log probabilities)\n",
    "        # log_softmax_Z = ...\n",
    "        log_sum_exp = torch.log(sum_exp_Z)\n",
    "        log_softmax_Z = Z_shifted - log_sum_exp\n",
    "\n",
    "        # TODO: Select the log-probabilities of the correct classes for each sample\n",
    "        # log_probs = ...\n",
    "        log_probs = log_softmax_Z[range(len(Y)), Y]\n",
    "\n",
    "        # TODO: Cross-entropy loss: average negative log-likelihood\n",
    "        # loss = ...\n",
    "        loss = -torch.mean(log_probs)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def backward(self, n_classes):\n",
    "        \"\"\"\n",
    "        Backward pass: compute the gradient of the loss with respect to logits Z.\n",
    "\n",
    "        Args:\n",
    "            n_classes (int): Number of classes in the classification problem.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Gradient dZ of shape (batch_size, n_classes).\n",
    "        \"\"\"\n",
    "        batch_size = len(self.Y)\n",
    "        # TODO: One-hot encode the true labels\n",
    "        # Y_one_hot = ...\n",
    "        # Y_one_hot = torch.zeros_like(self.A) # Alternativa\n",
    "        Y_one_hot = torch.zeros(batch_size, n_classes)\n",
    "        Y_one_hot[range(batch_size), self.Y] = 1\n",
    "\n",
    "        # TODO: Derivative of cross-entropy w.r.t logits: softmax_output - one_hot_labels\n",
    "        # dZ = ...\n",
    "        dZ = (self.A - Y_one_hot) / batch_size\n",
    "\n",
    "        return dZ\n",
    "\n",
    "# Example usage\n",
    "CELoss = CrossEntropyFromLogits()\n",
    "Y = torch.randint(0, 3, (n_batch,))\n",
    "loss = CELoss.forward(Z, Y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4lVIwb9YLCF"
   },
   "source": [
    "## 4. Training Loop — Forward, Backward, Manual Parameter Updates (No Optimizers Yet)\n",
    "\n",
    "In this section you’ll complete the **core learning cycle** using only the pieces we’ve built:\n",
    "1. **Forward pass:** compute logits \\(Z\\) from inputs \\(X\\).\n",
    "2. **Loss:** compute cross-entropy from logits and labels.\n",
    "3. **Backward (loss):** compute \\(dZ = \\partial \\mathcal{L} / \\partial Z\\) (vectorized).\n",
    "4. **Backward (network):** backpropagate \\(dZ\\) through layers to fill per-parameter grads.\n",
    "5. **Manual update:** call `net.update(learning_rate)` to apply **plain SGD** updates.\n",
    "\n",
    "### TODOs (what you must fill in)\n",
    "- [ ] **Forward:** `Z = net.forward(X)`\n",
    "- [ ] **Loss:** `loss = CELoss.forward(Z, Y)`\n",
    "- [ ] **Backward (loss):** `dZ = CELoss.backward(n_classes)`  (matrix form \\(A - Y\\); include \\(1/m\\) if you average)\n",
    "- [ ] **Backward (network):** `net.backward(dZ)`\n",
    "- [ ] **Update:** `net.update(learning_rate)`  *(manual SGD; no optimizer classes yet)*\n",
    "- [ ] **Metrics:** accumulate running loss/accuracy for train and val\n",
    "\n",
    "**Tips**\n",
    "- Average your **layer gradients** by batch size in each layer (e.g., `dW /= m`) for LR stability.\n",
    "- Keep **validation/test** forward-only (no `backward`, no `update`).\n",
    "- If you want to tweak LR per epoch, just modify the variable `learning_rate` before the loop or inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYINJm8iZakK"
   },
   "outputs": [],
   "source": [
    "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "batch_losses = []  # per-batch losses for the plot\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # -------- TRAIN --------\n",
    "    if hasattr(net, \"train\"): net.train()\n",
    "    running_loss, tot_correct, tot_samples = 0.0, 0, 0\n",
    "    total_batches = len(trainloader)\n",
    "\n",
    "    pbar = tqdm(trainloader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\")\n",
    "    for batch_idx, (images, labels) in enumerate(pbar, 1):\n",
    "        X = images.view(images.size(0), -1).to(device)\n",
    "        Y = labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        Z = Z = net.forward(X) #TODO\n",
    "        loss = CELoss.forward(Z, Y) #TODO\n",
    "\n",
    "        # Backward + update (manual autograd)\n",
    "        dZ = CELoss.backward(n_classes)  # TODO\n",
    "        _ = net.backward(dZ)  # TODO\n",
    "        net.update(learning_rate)  # TODO\n",
    "\n",
    "\n",
    "\n",
    "        # Stats\n",
    "        running_loss += loss.item() #TODO\n",
    "        batch_losses.append(loss.detach().cpu().item())\n",
    "        _, predicted = torch.max(Z, 1)\n",
    "        tot_correct += (predicted == Y).sum().item()\n",
    "        tot_samples += Y.size(0)\n",
    "\n",
    "        if batch_idx % max(1, total_batches // 10) == 0:\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\",\n",
    "                             acc=f\"{tot_correct / max(1, tot_samples):.4f}\")\n",
    "\n",
    "    train_loss = running_loss / len(trainloader)  # TODO\n",
    "    train_acc = tot_correct / tot_samples  # TODO\n",
    "\n",
    "    # -------- VALIDATION --------\n",
    "    if hasattr(net, \"eval\"): net.eval()\n",
    "    val_running_loss, val_correct, val_samples = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valloader, desc=f\"Epoch {epoch}/{num_epochs} [Val]\"):\n",
    "            X = images.view(images.size(0), -1).to(device)\n",
    "            Y = labels.to(device)\n",
    "\n",
    "            Z = net.forward(X)  # TODO\n",
    "            vloss = CELoss.forward(Z, Y)  # TODO\n",
    "            val_running_loss += vloss.item()  # TODO\n",
    "\n",
    "            _, predicted = torch.max(Z, 1)\n",
    "            val_correct += (predicted == Y).sum().item()\n",
    "            val_samples += Y.size(0)\n",
    "\n",
    "    val_loss = val_running_loss / len(valloader)\n",
    "    val_acc = val_correct / val_samples\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "# -------- OPTIONAL TEST --------\n",
    "if 'testloader' in globals() and testloader is not None:\n",
    "    if hasattr(net, \"eval\"): net.eval()\n",
    "    test_correct, test_samples, test_running_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(testloader, desc=\"[Test]\"):\n",
    "            X = images.view(images.size(0), -1).to(device)\n",
    "            Y = labels.to(device)\n",
    "            Z = net.forward(X) #TODO\n",
    "            loss = CELoss.forward(Z, Y)#TODO\n",
    "            test_running_loss += loss.item() #TODO\n",
    "            _, pred = torch.max(Z, 1)\n",
    "            test_correct += (pred == Y).sum().item()\n",
    "            test_samples += Y.size(0)\n",
    "    test_loss = test_running_loss / len(testloader)\n",
    "    test_acc = test_correct / test_samples\n",
    "    print(f\"[Test] Loss: {test_loss:.4f} | Acc: {test_acc:.4f}\")\n",
    "\n",
    "# -------- PLOTS --------\n",
    "plt.figure(); plt.plot(np.array(batch_losses))\n",
    "plt.xlabel('Batch'); plt.ylabel('Loss'); plt.title('Training Loss (per batch)'); plt.show()\n",
    "\n",
    "plt.figure(); plt.plot(history[\"train_loss\"], label='Train'); plt.plot(history[\"val_loss\"], label='Val')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss per Epoch'); plt.show()\n",
    "\n",
    "plt.figure(); plt.plot(history[\"train_acc\"], label='Train'); plt.plot(history[\"val_acc\"], label='Val')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.title('Accuracy per Epoch'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNZzsMcVd0Ro"
   },
   "source": [
    "## The `Net` Class: A Simple Sequential Container\n",
    "\n",
    "To organize our neural network, we define a `Net` class that acts as a **sequential container of layers**.  \n",
    "This class is inspired by frameworks like PyTorch, but implemented from scratch for educational purposes.\n",
    "\n",
    "### Key Responsibilities\n",
    "\n",
    "- **Layer Management:**  \n",
    "  We can add layers (e.g., `Linear`, `ReLU`, `Dropout`) using `add()`.  \n",
    "  Each layer must implement:\n",
    "  - `forward()` — computes the output given inputs.  \n",
    "  - `backward()` — computes the gradients of the loss w.r.t. its inputs.  \n",
    "  - `update(lr)` — updates the trainable parameters (if any).  \n",
    "\n",
    "- **Training/Evaluation Modes:**  \n",
    "  The class has `train()` and `eval()` methods.  \n",
    "  These switch the whole network into training or evaluation mode, propagating the setting to layers that support it (like `Dropout`, which behaves differently during training vs evaluation).\n",
    "\n",
    "- **Forward and Backward Passes:**  \n",
    "  - `forward(X)` runs the input through all layers in sequence.  \n",
    "  - `backward(dZ)` propagates gradients in reverse order, from the output back to the input.  \n",
    "\n",
    "- **Parameter Updates:**  \n",
    "  `update(lr)` applies gradient descent to all trainable layers, using the provided learning rate.  \n",
    "  (Later we could replace this with more advanced optimizers like Adam or RMSProp.)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **TODOs:**  \n",
    "  - Implement the details of each layer’s `forward()` and `backward()` functions.  \n",
    "  - Add parameter updates inside `update()` for layers that have weights.  \n",
    "  - Complete the training loop that uses this `Net` container to build and train a model on MNIST.  \n",
    "\n",
    "This design provides a clear and modular structure, making it easy to extend with new layers or optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1imEUcxliTJK"
   },
   "outputs": [],
   "source": [
    "class Net:\n",
    "    \"\"\"\n",
    "    A simple sequential container for custom layers.\n",
    "    Provides PyTorch-like train()/eval() switches and\n",
    "    runs forward/backward/update across all layers.\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Start with an empty list of layers and set the network\n",
    "        to training mode by default.\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        self.training = True  # True = training mode, False = eval mode\n",
    " \n",
    "    def add(self, layer):\n",
    "        \"\"\"\n",
    "        Add a layer to the network.\n",
    " \n",
    "        Args:\n",
    "            layer: Any object that implements forward(), backward(), update(),\n",
    "                   and (optionally) train()/eval() for mode control.\n",
    "        \"\"\"\n",
    "        self.layers.append(layer)\n",
    " \n",
    "    # ---- Mode control (pro-style) ----\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Switch the whole network to training mode and propagate\n",
    "        the setting to layers that implement train().\n",
    "        \"\"\"\n",
    "        self.training = True\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, \"train\"):\n",
    "                layer.train()\n",
    "        return self\n",
    " \n",
    "    def eval(self):\n",
    "        \"\"\"\n",
    "        Switch the whole network to evaluation mode and propagate\n",
    "        the setting to layers that implement eval().\n",
    "        \"\"\"\n",
    "        self.training = False\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, \"eval\"):\n",
    "                layer.eval()\n",
    "        return self\n",
    " \n",
    "    # ---- Core passes ----\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass through all layers.\n",
    " \n",
    "        Args:\n",
    "            X (torch.Tensor): Input to the network.\n",
    " \n",
    "        Returns:\n",
    "            torch.Tensor: Output after the last layer.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            #Implement the forward pass\n",
    "            X = layer.forward(X)  # TODO  # output of one layer becomes input to the next\n",
    "        return X\n",
    " \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        Backward pass through all layers in reverse order.\n",
    " \n",
    "        Args:\n",
    "            dZ (torch.Tensor): Gradient of the loss w.r.t. network output.\n",
    " \n",
    "        Returns:\n",
    "            torch.Tensor: Gradient of the loss w.r.t. the network input.\n",
    "        \"\"\"\n",
    "        for layer in reversed(self.layers):\n",
    "            #Implement the backward pass\n",
    "            dZ = layer.backward(dZ)  # TODO  # each layer returns grad for the previous one\n",
    "        return dZ\n",
    " \n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Update parameters of all trainable layers with the given learning rate.\n",
    " \n",
    "        Args:\n",
    "            lr (float): Learning rate.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            # Some layers (e.g., activations) may not have parameters\n",
    "            if hasattr(layer, \"update\"):\n",
    "                layer.update(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_jy5PSCm4on"
   },
   "source": [
    "### Testing the Implementation\n",
    "\n",
    "The following cells are intended as a **first test** of the network implementation.  \n",
    "We build a simple architecture with two linear layers and train it using our custom  \n",
    "cross-entropy loss. Since we have not yet introduced any **non-linear activation functions**,  \n",
    "this setup is equivalent to a **softmax regression model** (a linear classifier).  \n",
    "\n",
    "The purpose here is to verify that the forward pass, backward pass, parameter updates,  \n",
    "and loss tracking are working correctly before moving on to more complex networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Y0eoXyzjExZ"
   },
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set the device accordingly\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Forcing the device to CPU (this line will override the previous check)\n",
    "device = 'cpu'\n",
    "\n",
    "# Define the number of input features and output classes\n",
    "n_features = 784\n",
    "n_classes = 10\n",
    "num_epochs = 2\n",
    "\n",
    "# Initialize the network (assuming `Net` is a custom class that you've defined)\n",
    "net = Net()\n",
    "\n",
    "# Add a linear layer to the network with 784 input features and 1024 output features\n",
    "net.add(Linear(n_features, 1024, device=device))\n",
    "\n",
    "# Add another linear layer with 1024 input features and 10 output features\n",
    "net.add(Linear(1024, n_classes, device=device))\n",
    "\n",
    "# Initialize the custom cross-entropy loss function from logits\n",
    "CEloss = CrossEntropyFromLogits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqhIE7mKlTtO"
   },
   "outputs": [],
   "source": [
    "# Set the learning rate\n",
    "learning_rate = 0.001\n",
    "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "batch_losses = []  # per-batch losses for the plot\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # -------- TRAIN --------\n",
    "    if hasattr(net, \"train\"): net.train()\n",
    "    running_loss, tot_correct, tot_samples = 0.0, 0, 0\n",
    "    total_batches = len(trainloader)\n",
    "\n",
    "    pbar = tqdm(trainloader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\")\n",
    "    for batch_idx, (images, labels) in enumerate(pbar, 1):\n",
    "        X = images.view(images.size(0), -1).to(device)\n",
    "        Y = labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        Z = net.forward(X)\n",
    "        loss = CELoss.forward(Z, Y)\n",
    "\n",
    "        # Backward + update (manual autograd)\n",
    "        dZ = CELoss.backward(n_classes)\n",
    "        _ = net.backward(dZ)\n",
    "        net.update(learning_rate)\n",
    "\n",
    "        # Stats\n",
    "        running_loss += loss.item()\n",
    "        batch_losses.append(loss.detach().cpu().item())\n",
    "        _, predicted = torch.max(Z, 1)\n",
    "        tot_correct += (predicted == Y).sum().item()\n",
    "        tot_samples += Y.size(0)\n",
    "\n",
    "        if batch_idx % max(1, total_batches // 10) == 0:\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\",\n",
    "                             acc=f\"{tot_correct / max(1, tot_samples):.4f}\")\n",
    "\n",
    "    train_loss = running_loss / total_batches\n",
    "    train_acc = tot_correct / tot_samples\n",
    "\n",
    "    # -------- VALIDATION --------\n",
    "    if hasattr(net, \"eval\"): net.eval()\n",
    "    val_running_loss, val_correct, val_samples = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valloader, desc=f\"Epoch {epoch}/{num_epochs} [Val]\"):\n",
    "            X = images.view(images.size(0), -1).to(device)\n",
    "            Y = labels.to(device)\n",
    "\n",
    "            Z = net.forward(X)\n",
    "            vloss = CELoss.forward(Z, Y)\n",
    "            val_running_loss += vloss.item()\n",
    "\n",
    "            _, predicted = torch.max(Z, 1)\n",
    "            val_correct += (predicted == Y).sum().item()\n",
    "            val_samples += Y.size(0)\n",
    "\n",
    "    val_loss = val_running_loss / len(valloader)\n",
    "    val_acc = val_correct / val_samples\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "# -------- OPTIONAL TEST --------\n",
    "if 'testloader' in globals() and testloader is not None:\n",
    "    if hasattr(net, \"eval\"): net.eval()\n",
    "    test_correct, test_samples, test_running_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(testloader, desc=\"[Test]\"):\n",
    "            X = images.view(images.size(0), -1).to(device)\n",
    "            Y = labels.to(device)\n",
    "            Z = net.forward(X)\n",
    "            loss = CELoss.forward(Z, Y)\n",
    "            test_running_loss += loss.item()\n",
    "            _, pred = torch.max(Z, 1)\n",
    "            test_correct += (pred == Y).sum().item()\n",
    "            test_samples += Y.size(0)\n",
    "    test_loss = test_running_loss / len(testloader)\n",
    "    test_acc = test_correct / test_samples\n",
    "    print(f\"[Test] Loss: {test_loss:.4f} | Acc: {test_acc:.4f}\")\n",
    "\n",
    "# -------- PLOTS --------\n",
    "plt.figure(); plt.plot(np.array(batch_losses))\n",
    "plt.xlabel('Batch'); plt.ylabel('Loss'); plt.title('Training Loss (per batch)'); plt.show()\n",
    "\n",
    "plt.figure(); plt.plot(history[\"train_loss\"], label='Train'); plt.plot(history[\"val_loss\"], label='Val')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss per Epoch'); plt.show()\n",
    "\n",
    "plt.figure(); plt.plot(history[\"train_acc\"], label='Train'); plt.plot(history[\"val_acc\"], label='Val')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.title('Accuracy per Epoch'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t--JpzANm2Fz"
   },
   "source": [
    "### ReLU Activation Layer\n",
    "\n",
    "The **Rectified Linear Unit (ReLU)** is one of the most widely used activation functions in deep learning.  \n",
    "It introduces **non-linearity** into the network by applying a simple element-wise rule:\n",
    "\n",
    "$$\n",
    "a = \\text{ReLU}(z) = \\max(0, z)\n",
    "$$\n",
    "\n",
    "- **Forward Pass**:  \n",
    "  Each element of the input tensor \\( Z \\) is mapped to itself if it is positive, or zero if it is negative.  \n",
    "  This helps prevent the \"squashing\" effect of sigmoid/tanh and allows gradients to flow more effectively.\n",
    "\n",
    "- **Backward Pass**:  \n",
    "  The gradient is passed unchanged for inputs greater than zero and is set to zero for inputs less than or equal to zero:\n",
    "\n",
    "  $$\n",
    "  \\frac{\\partial a}{\\partial z} =\n",
    "  \\begin{cases}\n",
    "  1 & \\text{if } z > 0 \\\\\n",
    "  0 & \\text{if } z \\leq 0\n",
    "  \\end{cases}\n",
    "  $$\n",
    "\n",
    "- **Update Step**:  \n",
    "  ReLU has no trainable parameters, so its `update()` method is left empty.\n",
    "\n",
    "This layer is essential because it allows neural networks to model complex non-linear decision boundaries while remaining computationally efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmEUvk1dod-N"
   },
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \"\"\"\n",
    "    ReLU activation layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, Z):\n",
    "        \"\"\"\n",
    "        Perform the forward pass of the ReLU activation function.\n",
    "\n",
    "        Args:\n",
    "            Z (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            A torch.Tensor: Output tensor with ReLU applied element-wise.\n",
    "        \"\"\"\n",
    "        self.A = torch.maximum(Z, torch.zeros_like(Z)) #TODO\n",
    "        return self.A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Perform the backward pass of the ReLU activation function.\n",
    "\n",
    "        Args:\n",
    "            dA (torch.Tensor): Gradient of the loss with respect to the output.\n",
    "\n",
    "        Returns:\n",
    "            dZ torch.Tensor: Gradient of the loss with respect to the input.\n",
    "        \"\"\"\n",
    "        dZ = dA * (self.A > 0).float() #TODO\n",
    "\n",
    "        return dZ\n",
    "\n",
    "    def update(self,lr):\n",
    "        \"\"\"\n",
    "        ReLU does not have any parameters to update.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRQxxSRlph7k"
   },
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set the device accordingly\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Forcing the device to CPU (this line will override the previous check)\n",
    "device = 'cpu'\n",
    "\n",
    "# Define the number of input features and output classes\n",
    "n_features = 784\n",
    "n_classes = 10\n",
    "\n",
    "# Initialize the network (assuming `Net` is a custom class that you've defined)\n",
    "net = Net()\n",
    "\n",
    "# Add a linear layer to the network with 784 input features and 1024 output features\n",
    "net.add(Linear(n_features, 1024, device=device))\n",
    "\n",
    "# Add a non-linear activation function\n",
    "net.add(ReLU())\n",
    "\n",
    "# Add another linear layer with 1024 input features and 10 output features\n",
    "net.add(Linear(1024, n_classes, device=device))\n",
    "\n",
    "# Initialize the custom cross-entropy loss function from logits\n",
    "CEloss = CrossEntropyFromLogits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCBYBn9Dp5mv"
   },
   "outputs": [],
   "source": [
    "# Set the learning rate\n",
    "learning_rate = 0.001\n",
    "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "batch_losses = []  # per-batch losses for the plot\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # -------- TRAIN --------\n",
    "    if hasattr(net, \"train\"): net.train()\n",
    "    running_loss, tot_correct, tot_samples = 0.0, 0, 0\n",
    "    total_batches = len(trainloader)\n",
    "\n",
    "    pbar = tqdm(trainloader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\")\n",
    "    for batch_idx, (images, labels) in enumerate(pbar, 1):\n",
    "        X = images.view(images.size(0), -1).to(device)\n",
    "        Y = labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        Z = net.forward(X)\n",
    "        loss = CELoss.forward(Z, Y)\n",
    "\n",
    "        # Backward + update (manual autograd)\n",
    "        dZ = CELoss.backward(n_classes)\n",
    "        _ = net.backward(dZ)\n",
    "        net.update(learning_rate)\n",
    "\n",
    "        # Stats\n",
    "        running_loss += loss.item()\n",
    "        batch_losses.append(loss.detach().cpu().item())\n",
    "        _, predicted = torch.max(Z, 1)\n",
    "        tot_correct += (predicted == Y).sum().item()\n",
    "        tot_samples += Y.size(0)\n",
    "\n",
    "        if batch_idx % max(1, total_batches // 10) == 0:\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\",\n",
    "                             acc=f\"{tot_correct / max(1, tot_samples):.4f}\")\n",
    "\n",
    "    train_loss = running_loss / total_batches\n",
    "    train_acc = tot_correct / tot_samples\n",
    "\n",
    "    # -------- VALIDATION --------\n",
    "    if hasattr(net, \"eval\"): net.eval()\n",
    "    val_running_loss, val_correct, val_samples = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valloader, desc=f\"Epoch {epoch}/{num_epochs} [Val]\"):\n",
    "            X = images.view(images.size(0), -1).to(device)\n",
    "            Y = labels.to(device)\n",
    "\n",
    "            Z = net.forward(X)\n",
    "            vloss = CELoss.forward(Z, Y)\n",
    "            val_running_loss += vloss.item()\n",
    "\n",
    "            _, predicted = torch.max(Z, 1)\n",
    "            val_correct += (predicted == Y).sum().item()\n",
    "            val_samples += Y.size(0)\n",
    "\n",
    "    val_loss = val_running_loss / len(valloader)\n",
    "    val_acc = val_correct / val_samples\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "# -------- OPTIONAL TEST --------\n",
    "if 'testloader' in globals() and testloader is not None:\n",
    "    if hasattr(net, \"eval\"): net.eval()\n",
    "    test_correct, test_samples, test_running_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(testloader, desc=\"[Test]\"):\n",
    "            X = images.view(images.size(0), -1).to(device)\n",
    "            Y = labels.to(device)\n",
    "            Z = net.forward(X)\n",
    "            loss = CELoss.forward(Z, Y)\n",
    "            test_running_loss += loss.item()\n",
    "            _, pred = torch.max(Z, 1)\n",
    "            test_correct += (pred == Y).sum().item()\n",
    "            test_samples += Y.size(0)\n",
    "    test_loss = test_running_loss / len(testloader)\n",
    "    test_acc = test_correct / test_samples\n",
    "    print(f\"[Test] Loss: {test_loss:.4f} | Acc: {test_acc:.4f}\")\n",
    "\n",
    "# -------- PLOTS --------\n",
    "plt.figure(); plt.plot(np.array(batch_losses))\n",
    "plt.xlabel('Batch'); plt.ylabel('Loss'); plt.title('Training Loss (per batch)'); plt.show()\n",
    "\n",
    "plt.figure(); plt.plot(history[\"train_loss\"], label='Train'); plt.plot(history[\"val_loss\"], label='Val')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss per Epoch'); plt.show()\n",
    "\n",
    "plt.figure(); plt.plot(history[\"train_acc\"], label='Train'); plt.plot(history[\"val_acc\"], label='Val')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.title('Accuracy per Epoch'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L94-47vRosR6"
   },
   "source": [
    "### Extending the Neural Network\n",
    "\n",
    "At this point, we have implemented the essential components of a neural network:  \n",
    "- **Linear transformations (fully connected layers)** to project data into new spaces,  \n",
    "- **Non-linear activation functions** such as ReLU to introduce complexity and allow the network to model non-linear relationships, and  \n",
    "- **A cost function (e.g., Cross-Entropy)** to measure the discrepancy between predictions and true labels.  \n",
    "\n",
    "While this setup already allows us to train a functional neural network, more advanced operations can significantly improve performance and generalization. Two of the most important techniques are:  \n",
    "\n",
    "- **Dropout**: Randomly disables a fraction of neurons during training, preventing co-adaptation and reducing overfitting.  \n",
    "- **Batch Normalization**: Normalizes intermediate activations across a mini-batch, stabilizing training and often accelerating convergence.  \n",
    "\n",
    "Adding these operations will bring our implementation closer to modern deep learning practices, making the models both more robust and efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GxeamCV5qEY"
   },
   "source": [
    "### Batch Normalization\n",
    "\n",
    "Batch Normalization (BN) is used to stabilize and accelerate training by normalizing activations.  \n",
    "Given input activations $X \\in \\mathbb{R}^{m \\times d}$ (batch size $m$, features $d$):\n",
    "\n",
    "---\n",
    "\n",
    "**Training mode**\n",
    "\n",
    "Batch statistics:  \n",
    "$$\n",
    "\\mu_{\\mathrm{B}}=\\frac{1}{m}\\sum_{i=1}^m X_i\n",
    "$$  \n",
    "$$\n",
    "\\sigma^2_{\\mathrm{B}}=\\frac{1}{m}\\sum_{i=1}^m \\left(X_i-\\mu_{\\mathrm{B}}\\right)^2\n",
    "$$\n",
    "\n",
    "Normalize, then scale/shift:  \n",
    "$$\n",
    "\\hat{X}_i=\\frac{X_i-\\mu_{\\mathrm{B}}}{\\sqrt{\\sigma^2_{\\mathrm{B}}+\\varepsilon}}\n",
    "$$  \n",
    "$$\n",
    "Y_i=\\gamma\\,\\hat{X}_i+\\beta\n",
    "$$\n",
    "\n",
    "Update running (EMA) statistics with momentum $\\alpha$:  \n",
    "$$\n",
    "\\mu_{\\mathrm{R}} \\leftarrow (1-\\alpha)\\,\\mu_{\\mathrm{R}} + \\alpha\\,\\mu_{\\mathrm{B}}\n",
    "$$  \n",
    "$$\n",
    "\\sigma^2_{\\mathrm{R}} \\leftarrow (1-\\alpha)\\,\\sigma^2_{\\mathrm{R}} + \\alpha\\,\\sigma^2_{\\mathrm{B}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Inference mode**\n",
    "\n",
    "Use stored running statistics (no updates):  \n",
    "$$\n",
    "\\hat{X}_i=\\frac{X_i-\\mu_{\\mathrm{R}}}{\\sqrt{\\sigma^2_{\\mathrm{R}}+\\varepsilon}}\n",
    "$$  \n",
    "$$\n",
    "Y_i=\\gamma\\,\\hat{X}_i+\\beta\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**  \n",
    "- **Training:** use $(\\mu_{\\mathrm{B}}, \\sigma^2_{\\mathrm{B}})$, normalize, scale/shift, update $(\\mu_{\\mathrm{R}}, \\sigma^2_{\\mathrm{R}})$.  \n",
    "- **Inference:** use $(\\mu_{\\mathrm{R}}, \\sigma^2_{\\mathrm{R}})$ collected during training, normalize, scale/shift, **no updates**.\n",
    "\n",
    "---\n",
    "\n",
    "### Task\n",
    "\n",
    "Implement **BatchNorm as a class** with the following:\n",
    "\n",
    "- **Forward pass (`forward`)**  \n",
    "  - #TODO compute batch mean $\\mu_{\\mathrm{B}}$ and variance $\\sigma^2_{\\mathrm{B}}$ (training)  \n",
    "  - #TODO normalize input $X$  \n",
    "  - #TODO scale and shift using $\\gamma, \\beta$  \n",
    "  - #TODO update running mean/variance (training only)  \n",
    "  - #TODO use running statistics in inference mode  \n",
    "\n",
    "- **Backward pass (`backward`)**  \n",
    "  - #TODO compute gradient of loss w.r.t. $\\hat{X}$  \n",
    "  - #TODO propagate through normalization to get $dX$  \n",
    "  - #TODO compute gradients w.r.t. parameters $\\gamma, \\beta$  \n",
    "\n",
    "- **Update parameters (`update`)**  \n",
    "  - #TODO update $\\gamma, \\beta$ using the learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lu09TUDa5Re_"
   },
   "outputs": [],
   "source": [
    "class BatchNorm1D:\n",
    "    \"\"\"\n",
    "    Batch Normalization for 2D inputs: (batch, features).\n",
    " \n",
    "    TRAIN: compute batch stats, normalize, update running stats, support backward().\n",
    "    EVAL:  use running stats, no updates, typically no backward().\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, n_features, eps=1e-5, momentum=0.1, device=\"cpu\"):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.device = device\n",
    " \n",
    "        # Learnable affine parameters\n",
    "        self.gamma = torch.ones(n_features, device=device, requires_grad=False)\n",
    "        self.beta  = torch.zeros(n_features, device=device, requires_grad=False)\n",
    " \n",
    "        # Running (inference) statistics\n",
    "        self.running_mean = torch.zeros(n_features, device=device, requires_grad=False)\n",
    "        self.running_var  = torch.ones(n_features,  device=device, requires_grad=False)\n",
    " \n",
    "        # Mode flag\n",
    "        self.training = True\n",
    " \n",
    "        # Caches for backward\n",
    "        self.X = None\n",
    "        self.X_hat = None\n",
    "        self.batch_mean = None\n",
    "        self.batch_var = None\n",
    "        self.std = None\n",
    " \n",
    "        # Grads for parameters\n",
    "        self.dgamma = None\n",
    "        self.dbeta  = None\n",
    " \n",
    "    def train(self): self.training = True;  return self\n",
    "    def eval(self):  self.training = False; return self\n",
    " \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: (batch, features)\n",
    "        Returns:\n",
    "            Y: (batch, features)\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            # ===== TODO: compute batch statistics along batch dim =====\n",
    "            self.batch_mean = torch.mean(X, dim=0)\n",
    "            self.batch_var = torch.var(X, dim=0, unbiased=False)   # use unbiased=False\n",
    "            # ===== TODO: compute std and normalized activations =====\n",
    "            self.std = torch.sqrt(self.batch_var + self.eps)\n",
    "            self.X_hat = (X - self.batch_mean) / self.std\n",
    "            #\n",
    "            # ===== TODO: update running stats (EMA) =====\n",
    "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * self.batch_mean\n",
    "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * self.batch_var\n",
    "        else:\n",
    "            # ===== TODO: inference normalization using running stats =====\n",
    "            self.std = torch.sqrt(self.running_var + self.eps)\n",
    "            self.X_hat = (X - self.running_mean) / self.std\n",
    " \n",
    "        # Cache input for backward\n",
    "        self.X = X\n",
    " \n",
    "        # ===== TODO: affine transform Y = gamma * X_hat + beta =====\n",
    "        Y = self.gamma * self.X_hat + self.beta\n",
    "        return Y\n",
    " \n",
    "    def backward(self, dY):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dY: upstream gradient (batch, features)\n",
    "        Returns:\n",
    "            dX: gradient wrt input X (batch, features)\n",
    "        \"\"\"\n",
    "        if not self.training:\n",
    "            # In this teaching framework we forbid backward in eval to emphasize the distinction.\n",
    "            raise RuntimeError(\"Backward called in eval() mode. Use training mode for gradient computation.\")\n",
    " \n",
    "        m = dY.size(0)  # batch size\n",
    " \n",
    "        # ===== TODO: parameter gradients =====\n",
    "        self.dgamma = torch.sum(dY * self.X_hat, dim=0)\n",
    "        self.dbeta  = torch.sum(dY, dim=0)\n",
    " \n",
    "        # ===== TODO: gradient wrt normalized activations =====\n",
    "        dx_hat = dY * self.gamma\n",
    " \n",
    "        # The following hints reflect the standard BN backward derivation:\n",
    "        x_mu   = self.X - self.batch_mean\n",
    "        invstd = 1.0 / self.std\n",
    "        #\n",
    "        # ===== TODO: compute dvar and dmean using cached tensors =====\n",
    "        dvar  = torch.sum(dx_hat * x_mu * -0.5 * (invstd ** 3), dim=0)\n",
    "        dmean = torch.sum(-dx_hat * invstd, dim=0) + dvar * torch.mean(-2.0 * x_mu, dim=0)\n",
    "        #\n",
    "        # ===== TODO: put it all together to get dX =====\n",
    "        dX = dx_hat * invstd + (2.0 / m) * x_mu * dvar + dmean / m\n",
    "        #\n",
    "        return dX\n",
    "        \n",
    " \n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Simple SGD update for gamma and beta.\n",
    "        \"\"\"\n",
    "        # ===== TODO: apply SGD step to gamma and beta =====\n",
    "        self.gamma -= lr * self.dgamma\n",
    "        self.beta  -= lr * self.dbeta\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtu3_Meh8eBH"
   },
   "source": [
    "### Inverted Dropout ###\n",
    "\n",
    "Let:  \n",
    "$ p = \\text{drop probability (fraction of units set to zero in training)}$\n",
    "$ q = 1-p = \\text{keep probability} $\n",
    "$ X \\in \\mathbb{R}^{m \\times d} = \\text{activations (batch } m, \\text{ features } d) $\n",
    "$ M \\in \\left\\{ 0, \\frac{1}{q} \\right\\}^{m \\times d} = \\text{dropout mask} $\n",
    "\n",
    "---\n",
    "\n",
    "**Training mode:**\n",
    "\n",
    "We sample the mask $$ M $$ as:\n",
    "$$\n",
    "M_{ij} =\n",
    "\\begin{cases}\n",
    "\\frac{1}{q}, & \\text{with probability } q, \\\\\n",
    "0, & \\text{with probability } p\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Then the output is:\n",
    "$$\n",
    "Y = X \\odot M\n",
    "$$\n",
    "\n",
    "**Expected value during training:**\n",
    "$$\n",
    "\\mathbb{E}[Y] = \\mathbb{E}[X \\odot M] = X \\cdot \\mathbb{E}[M] = X \\cdot \\left(q \\cdot \\frac{1}{q} + p \\cdot 0\\right) = X\n",
    "$$\n",
    "\n",
    "Thus, the expected activations in training match those in inference.\n",
    "\n",
    "---\n",
    "\n",
    "**Inference mode:**\n",
    "\n",
    "No dropout, no scaling:\n",
    "$$\n",
    "Y = X\n",
    "$$\n",
    "\n",
    "Since training already scaled the kept units by $$ \\tfrac{1}{q} $$, the magnitude matches without extra work.\n",
    "\n",
    "---\n",
    "\n",
    "**Why not multiply by $ p $?**\n",
    "\n",
    "Multiplying by $ p $ would shrink the kept activations instead of preserving their expected value:\n",
    "$$\n",
    "\\mathbb{E}[Y] = X \\cdot p \\quad \\neq \\quad X\n",
    "$$\n",
    "\n",
    "That would require extra scaling at inference, which *inverted dropout* avoids.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "**Training:**  \n",
    "$$\n",
    "Y = X \\odot M, \\quad M_{ij} \\in \\left\\{0, \\tfrac{1}{1-p}\\right\\}\n",
    "$$\n",
    "\n",
    "**Inference:**  \n",
    "$$\n",
    "Y = X\n",
    "$$\n",
    "\n",
    "Property preserved:  \n",
    "$$\n",
    "\\mathbb{E}[Y] = X\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Task\n",
    "\n",
    "- Implement an **`Inverted Dropout`** layer with the following methods:  \n",
    "  - `forward(X)`:  \n",
    "    - In **training mode**, apply mask $$ M $$ as above.  \n",
    "    - In **evaluation mode**, return $$ X $$.  \n",
    "  - `backward(dY)`: propagate gradients through the same mask.  \n",
    "  - `train()` / `eval()`: toggle between training and inference modes.  \n",
    "  - `update(lr)`: no parameters to update, but include for API consistency.  \n",
    "\n",
    "- Verify by simulation that:  \n",
    "  1. The expected output of the dropout layer in **training** matches the original input.  \n",
    "  2. No scaling is needed in **evaluation**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-ePO-1o7-_x"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Dropout:\n",
    "    \"\"\"\n",
    "    Inverted Dropout (for fully-connected tensors [batch, features]).\n",
    "\n",
    "    - TRAIN: randomly zeroes activations with prob p, and rescales by 1/(1-p)\n",
    "             so the expected activation stays constant.\n",
    "    - EVAL:  identity (no dropout, no scaling).\n",
    "\n",
    "    Students must implement the forward and backward passes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p (float): Drop probability in [0,1). Typical values: 0.1~0.5\n",
    "            device (str): 'cpu' or 'cuda'\n",
    "        \"\"\"\n",
    "        assert 0.0 <= p < 1.0, \"p must be in [0, 1).\"\n",
    "        self.p = p\n",
    "        self.device = device\n",
    "        self.training = True\n",
    "        self.mask = None  # cache for backward\n",
    "\n",
    "    # Mode control\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        self.training = False\n",
    "        return self\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass of dropout.\n",
    "\n",
    "        Args:\n",
    "            X: Tensor of shape (batch, features)\n",
    "        Returns:\n",
    "            Tensor of same shape\n",
    "        \"\"\"\n",
    "        if self.training and self.p > 0.0:\n",
    "            # TODO: Implement inverted dropout\n",
    "            # 1. Compute keep_prob = 1 - p\n",
    "            # 2. Sample a Bernoulli mask with probability keep_prob\n",
    "            # 3. Scale the mask by 1 / keep_prob\n",
    "            # 4. Multiply X by the mask and return\n",
    "            keep_prob = 1.0 - self.p\n",
    "            self.mask = (torch.rand_like(X) < keep_prob).float()\n",
    "            self.mask /= keep_prob  # Scale by 1/keep_prob\n",
    "            return X * self.mask\n",
    "        else:\n",
    "            # TODO: In eval mode, dropout is a no-op\n",
    "            # Return X unchanged and store a mask of ones for backward\n",
    "            self.mask = torch.ones_like(X)\n",
    "            return X\n",
    "\n",
    "    def backward(self, dY):\n",
    "        \"\"\"\n",
    "        Backward pass of dropout.\n",
    "\n",
    "        Args:\n",
    "            dY: Gradient wrt output, shape (batch, features)\n",
    "        Returns:\n",
    "            dX: Gradient wrt input, shape (batch, features)\n",
    "        \"\"\"\n",
    "        # TODO: Backprop through dropout\n",
    "        # TRAIN: dX = dY * mask\n",
    "        # EVAL:  dX = dY\n",
    "        return dY * self.mask\n",
    "\n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        No learnable parameters in Dropout, so nothing to update.\n",
    "        Kept for API consistency.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjxeufrGs7HS"
   },
   "source": [
    "## Final Task — Put It All Together\n",
    "\n",
    "In this capstone exercise you will **assemble a complete mini deep-learning stack** and use it to train MNIST models. You’ll integrate **Linear**, **ReLU**, **BatchNorm1D**, and **Dropout**, write a clean **training/validation loop**, experiment with **different architectures**, and finally **package your code** into a reusable Python module.\n",
    "\n",
    "### What to Build\n",
    "\n",
    "1. **Model Architectures (experiment)**\n",
    "   - Start with a baseline: `Linear(784→10)` (softmax regression).\n",
    "   - Add depth + non-linearities:\n",
    "     - Example A: `Linear(784→256) → ReLU → Linear(256→10)`\n",
    "     - Example B: `Linear(784→256) → BatchNorm1D → ReLU → Dropout(p=0.2) → Linear(256→10)`\n",
    "     - Example C (deeper): `784→512→BatchNorm→ReLU→Dropout→256→BatchNorm→ReLU→Dropout→10`\n",
    "   - Try **2–3 architectures**. Log train/val loss & accuracy per epoch.\n",
    "\n",
    "2. **Training Loop (manual updates, no optimizers yet)**\n",
    "   - Forward → Loss (CrossEntropyFromLogits) → Backward (matrix form) → `net.backward(dZ)` → `net.update(lr)`.\n",
    "   - Validation after each epoch (no grads, no updates).\n",
    "   - Record to `history = {\"train_loss\",\"train_acc\",\"val_loss\",\"val_acc\"}`.\n",
    "   - Plots: per-batch loss; per-epoch loss/accuracy (train vs. val).\n",
    "\n",
    "3. **Regularization & Stabilization**\n",
    "   - **Dropout:** compare `p ∈ {0.0, 0.2, 0.5}`.\n",
    "   - **BatchNorm:** place BN **before** ReLU in FC blocks (common practice).\n",
    "   - Optional extras (if time): weight decay (L2), gradient clipping, LR schedule.\n",
    "\n",
    "4. **Packaging Your Framework**\n",
    "   - Create a single file **`minitorch.py`** with all components:\n",
    "     - Layers: `Linear`, `ReLU`, `BatchNorm1D`, `Dropout`\n",
    "     - Loss: `CrossEntropyFromLogits`\n",
    "     - Container: `Net`\n",
    "     - (Optional) utility functions (e.g., accuracy)\n",
    "   - Import it from your notebook and train.\n",
    "\n",
    "---\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "- **Notebook results:**\n",
    "  - Table or brief summary of architectures tried, best val accuracy, and comments.\n",
    "  - Training curves (loss & accuracy) showing the effect of BN/Dropout.\n",
    "- **`minitorch.py`** file with clean docstrings and minimal dependencies.\n",
    "\n",
    "---\n",
    "\n",
    "### Suggested Evaluation Protocol\n",
    "\n",
    "- Use the same **train/val split** across runs (fix a seed).\n",
    "- Train for **~5–10 epochs** (enough to see trends).\n",
    "- Report **best validation accuracy** and final **test accuracy** for your top model.\n",
    "- Briefly explain **what helped** (BN, Dropout, depth) and **why**.\n",
    "\n",
    "---\n",
    "\n",
    "### Checklist / TODOs\n",
    "\n",
    "- [ ] Implement **forward** and **backward** in `Linear`, `ReLU`, `BatchNorm1D`, `Dropout`.\n",
    "- [ ] Implement **CrossEntropyFromLogits** with vectorized gradient \\(dZ = A - Y\\).\n",
    "- [ ] Write training loop with **manual parameter updates** (`net.update(lr)`).\n",
    "- [ ] Add **BatchNorm** and **Dropout** in your architectures and compare.\n",
    "- [ ] Track and plot **history** for train/val.\n",
    "- [ ] Save best model metrics and briefly **analyze results**.\n",
    "- [ ] Package everything into **`minitorch.py`** and re-run using imports.\n",
    "\n",
    "---\n",
    "\n",
    "### Example `minitorch.py` Skeleton (fill in your implementations)\n",
    "\n",
    "```python\n",
    "# minitorch.py\n",
    "import torch\n",
    "\n",
    "class Net:\n",
    "    def __init__(self): self.layers=[]; self.training=True\n",
    "    def add(self, layer): self.layers.append(layer)\n",
    "    def train(self): self.training=True; [getattr(l,'train',lambda:None)() for l in self.layers]; return self\n",
    "    def eval(self):  self.training=False;[getattr(l,'eval', lambda:None)() for l in self.layers]; return self\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers: X = layer.forward(X)\n",
    "        return X\n",
    "    def backward(self, dZ):\n",
    "        for layer in reversed(self.layers): dZ = layer.backward(dZ)\n",
    "        return dZ\n",
    "    def update(self, lr):\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, \"update\"): layer.update(lr)\n",
    "\n",
    "class Linear:\n",
    "    # TODO: init (W,b), forward, backward (avg grads), update, parameters (optional)\n",
    "    ...\n",
    "\n",
    "class ReLU:\n",
    "    # TODO: forward (max(0,z)), backward (mask), update (pass)\n",
    "    ...\n",
    "\n",
    "class BatchNorm1D:\n",
    "    # TODO: forward (train/infer paths, EMA), backward (γ, β, dX), update\n",
    "    ...\n",
    "\n",
    "class Dropout:\n",
    "    # TODO: forward (inverted dropout), backward (mask), update (pass)\n",
    "    ...\n",
    "\n",
    "class CrossEntropyFromLogits:\n",
    "    # TODO: forward (softmax/log-softmax + NLL), backward (A - one_hot(Y))\n",
    "    ...\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOF7b9okUGKeOvqnSDoagLe",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
